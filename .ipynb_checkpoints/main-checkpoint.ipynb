{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ddbe49b",
   "metadata": {},
   "source": [
    "### Задание 1\n",
    "##### Импортируйте библиотеки pandas, numpy и matplotlib.\n",
    "#####  Загрузите \"Boston House Prices dataset\" из встроенных наборов \n",
    "##### данных библиотеки sklearn.\n",
    "##### Создайте датафреймы X и y из этих данных.\n",
    "##### Разбейте эти датафреймы на тренировочные (X_train, y_train) и тестовые (X_test, y_test)\n",
    "##### с помощью функции train_test_split так, чтобы размер тестовой выборки\n",
    "##### составлял 20% от всех данных, при этом аргумент random_state должен быть равен 42.\n",
    "##### Масштабируйте данные с помощью StandardScaler.\n",
    "##### Постройте модель TSNE на тренировочный данных с параметрами:\n",
    "##### n_components=2, learning_rate=250, random_state=42.\n",
    "##### Постройте диаграмму рассеяния на этих данных.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3b1d7e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9583f479",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\миша программирование\\python\\venv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c834acda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
      "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
      "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
      "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
      "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
      "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
      "\n",
      "   PTRATIO       B  LSTAT  \n",
      "0     15.3  396.90   4.98  \n",
      "1     17.8  396.90   9.14  \n",
      "2     17.8  392.83   4.03  \n",
      "3     18.7  394.63   2.94  \n",
      "4     18.7  396.90   5.33  \n",
      "\n",
      "\n",
      "\n",
      "   price\n",
      "0   24.0\n",
      "1   21.6\n",
      "2   34.7\n",
      "3   33.4\n",
      "4   36.2\n"
     ]
    }
   ],
   "source": [
    "X = pd.DataFrame(boston['data'], columns=boston['feature_names'])\n",
    "y = pd.DataFrame(boston['target'], columns=['price'])\n",
    "print(X.head(), y.head(), sep='\\n\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "be8c1130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         CRIM    ZN  INDUS  CHAS     NOX     RM   AGE     DIS   RAD    TAX  \\\n",
      "477  15.02340   0.0  18.10   0.0  0.6140  5.304  97.3  2.1007  24.0  666.0   \n",
      "15    0.62739   0.0   8.14   0.0  0.5380  5.834  56.5  4.4986   4.0  307.0   \n",
      "332   0.03466  35.0   6.06   0.0  0.4379  6.031  23.3  6.6407   1.0  304.0   \n",
      "423   7.05042   0.0  18.10   0.0  0.6140  6.103  85.1  2.0218  24.0  666.0   \n",
      "19    0.72580   0.0   8.14   0.0  0.5380  5.727  69.5  3.7965   4.0  307.0   \n",
      "..        ...   ...    ...   ...     ...    ...   ...     ...   ...    ...   \n",
      "106   0.17120   0.0   8.56   0.0  0.5200  5.836  91.9  2.2110   5.0  384.0   \n",
      "270   0.29916  20.0   6.96   0.0  0.4640  5.856  42.1  4.4290   3.0  223.0   \n",
      "348   0.01501  80.0   2.01   0.0  0.4350  6.635  29.7  8.3440   4.0  280.0   \n",
      "435  11.16040   0.0  18.10   0.0  0.7400  6.629  94.6  2.1247  24.0  666.0   \n",
      "102   0.22876   0.0   8.56   0.0  0.5200  6.405  85.4  2.7147   5.0  384.0   \n",
      "\n",
      "     PTRATIO       B  LSTAT  \n",
      "477     20.2  349.48  24.91  \n",
      "15      21.0  395.62   8.47  \n",
      "332     16.9  362.25   7.83  \n",
      "423     20.2    2.52  23.29  \n",
      "19      21.0  390.95  11.28  \n",
      "..       ...     ...    ...  \n",
      "106     20.9  395.67  18.66  \n",
      "270     18.6  388.65  13.00  \n",
      "348     17.0  390.94   5.99  \n",
      "435     20.2  109.85  23.27  \n",
      "102     20.9   70.80  10.63  \n",
      "\n",
      "[404 rows x 13 columns]\n",
      "\n",
      "\n",
      "\n",
      "         CRIM    ZN  INDUS  CHAS    NOX     RM    AGE     DIS   RAD    TAX  \\\n",
      "173   0.09178   0.0   4.05   0.0  0.510  6.416   84.1  2.6463   5.0  296.0   \n",
      "274   0.05644  40.0   6.41   1.0  0.447  6.758   32.9  4.0776   4.0  254.0   \n",
      "491   0.10574   0.0  27.74   0.0  0.609  5.983   98.8  1.8681   4.0  711.0   \n",
      "72    0.09164   0.0  10.81   0.0  0.413  6.065    7.8  5.2873   4.0  305.0   \n",
      "452   5.09017   0.0  18.10   0.0  0.713  6.297   91.8  2.3682  24.0  666.0   \n",
      "..        ...   ...    ...   ...    ...    ...    ...     ...   ...    ...   \n",
      "412  18.81100   0.0  18.10   0.0  0.597  4.628  100.0  1.5539  24.0  666.0   \n",
      "436  14.42080   0.0  18.10   0.0  0.740  6.461   93.3  2.0026  24.0  666.0   \n",
      "411  14.05070   0.0  18.10   0.0  0.597  6.657  100.0  1.5275  24.0  666.0   \n",
      "86    0.05188   0.0   4.49   0.0  0.449  6.015   45.1  4.4272   3.0  247.0   \n",
      "75    0.09512   0.0  12.83   0.0  0.437  6.286   45.0  4.5026   5.0  398.0   \n",
      "\n",
      "     PTRATIO       B  LSTAT  \n",
      "173     16.6  395.50   9.04  \n",
      "274     17.6  396.90   3.53  \n",
      "491     20.1  390.11  18.07  \n",
      "72      19.2  390.91   5.52  \n",
      "452     20.2  385.09  17.27  \n",
      "..       ...     ...    ...  \n",
      "412     20.2   28.79  34.37  \n",
      "436     20.2   27.49  18.05  \n",
      "411     20.2   35.05  21.22  \n",
      "86      18.5  395.99  12.86  \n",
      "75      18.7  383.23   8.94  \n",
      "\n",
      "[102 rows x 13 columns]\n",
      "\n",
      "\n",
      "\n",
      "     price\n",
      "477   12.0\n",
      "15    19.9\n",
      "332   19.4\n",
      "423   13.4\n",
      "19    18.2\n",
      "..     ...\n",
      "106   19.5\n",
      "270   21.1\n",
      "348   24.5\n",
      "435   13.4\n",
      "102   18.6\n",
      "\n",
      "[404 rows x 1 columns]\n",
      "\n",
      "\n",
      "\n",
      "     price\n",
      "173   23.6\n",
      "274   32.4\n",
      "491   13.6\n",
      "72    22.8\n",
      "452   16.1\n",
      "..     ...\n",
      "412   17.9\n",
      "436    9.6\n",
      "411   17.2\n",
      "86    22.5\n",
      "75    21.4\n",
      "\n",
      "[102 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, y_train, X_test, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(X_train, y_train, X_test, y_test, sep='\\n\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "16f5274d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\миша программирование\\python\\venv\\lib\\site-packages\\sklearn\\base.py:488: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- price\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- AGE\n",
      "- B\n",
      "- CHAS\n",
      "- CRIM\n",
      "- DIS\n",
      "- ...\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 1 features, but StandardScaler is expecting 13 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Temp/ipykernel_26332/2271853294.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mX_train_scaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mboston\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'feature_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mX_test_scaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mboston\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'feature_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\n\\n\\n\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\миша программирование\\python\\venv\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m    971\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    972\u001b[0m         \u001b[0mcopy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 973\u001b[1;33m         X = self._validate_data(\n\u001b[0m\u001b[0;32m    974\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m             \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\миша программирование\\python\\venv\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    578\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ensure_2d\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\миша программирование\\python\\venv\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 395\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    396\u001b[0m                 \u001b[1;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    397\u001b[0m                 \u001b[1;34mf\"is expecting {self.n_features_in_} features as input.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: X has 1 features, but StandardScaler is expecting 13 features as input."
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train_scaled = pd.DataFrame(sc.fit_transform(X_train), columns=boston['feature_names'])\n",
    "X_test_scaled = pd.DataFrame(sc.transform(X_test), columns=boston['feature_names'])\n",
    "print(X_train_scaled, X_test_scaled, sep='\\n\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01142f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=2, learning_rate=250, random_state=42)\n",
    "X_train_tsne = tsne.fit_transform(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf910327",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train_tsne[:, 0], X_train_tsne[:, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3fdf24",
   "metadata": {},
   "source": [
    "### Задание 2\n",
    "##### С помощью KMeans разбейте данные из тренировочного набора на 3 кластера,\n",
    "##### используйте все признаки из датафрейма X_train.\n",
    "##### Параметр max_iter должен быть равен 100, random_state сделайте равным 42.\n",
    "##### Постройте еще раз диаграмму рассеяния на данных, полученных с помощью TSNE,\n",
    "##### и раскрасьте точки из разных кластеров разными цветами.\n",
    "##### Вычислите средние значения price и CRIM в разных кластерах.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a03d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "model = KMeans(n_clusters=3, max_iter=100, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b84340",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = model.fit_predict(X_train)\n",
    "plt.scatter(X_train_tsne[:, 0], X_train_tsne[:, 1], c=labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94988cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    print(np.mean(X_train['CRIM'][labels == i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7bbb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    print(np.mean(y_train[labels == i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
